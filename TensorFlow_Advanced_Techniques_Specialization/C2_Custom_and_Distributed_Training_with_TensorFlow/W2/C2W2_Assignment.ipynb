{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AWqcoPhU3RJN"
   },
   "source": [
    "# Breast Cancer Prediction\n",
    "\n",
    "In this exercise, you will train a neural network on the [Breast Cancer Dataset](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)) to predict if the tumor is malignant or benign.\n",
    "\n",
    "If you get stuck, we recommend that you review the ungraded labs for this week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "st5AIBFZ5mEQ"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkMXve8XuN5X"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUc3HpEQ5s6U"
   },
   "source": [
    "## Load and Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-TQFUXu5wS_"
   },
   "source": [
    "We first load the dataset and create a data frame using pandas. We explicitly specify the column names because the CSV file does not have column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVh-W73J5TjS"
   },
   "outputs": [],
   "source": [
    "data_file = './data/data.csv'\n",
    "col_names = [\"id\", \"clump_thickness\", \"un_cell_size\", \"un_cell_shape\", \"marginal_adheshion\", \"single_eph_cell_size\", \"bare_nuclei\", \"bland_chromatin\", \"normal_nucleoli\", \"mitoses\", \"class\"]\n",
    "df = pd.read_csv(data_file, names=col_names, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEv8vS_P6HaV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>un_cell_size</th>\n",
       "      <th>un_cell_shape</th>\n",
       "      <th>marginal_adheshion</th>\n",
       "      <th>single_eph_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1018099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1018561</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1033078</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1033078</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1035283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1036172</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1041801</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1043999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1044572</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1047630</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1048672</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1049815</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1050670</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1050718</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  clump_thickness  un_cell_size  un_cell_shape  marginal_adheshion  \\\n",
       "0   1000025                5             1              1                   1   \n",
       "1   1002945                5             4              4                   5   \n",
       "2   1015425                3             1              1                   1   \n",
       "3   1016277                6             8              8                   1   \n",
       "4   1017023                4             1              1                   3   \n",
       "5   1017122                8            10             10                   8   \n",
       "6   1018099                1             1              1                   1   \n",
       "7   1018561                2             1              2                   1   \n",
       "8   1033078                2             1              1                   1   \n",
       "9   1033078                4             2              1                   1   \n",
       "10  1035283                1             1              1                   1   \n",
       "11  1036172                2             1              1                   1   \n",
       "12  1041801                5             3              3                   3   \n",
       "13  1043999                1             1              1                   1   \n",
       "14  1044572                8             7              5                  10   \n",
       "15  1047630                7             4              6                   4   \n",
       "16  1048672                4             1              1                   1   \n",
       "17  1049815                4             1              1                   1   \n",
       "18  1050670               10             7              7                   6   \n",
       "19  1050718                6             1              1                   1   \n",
       "\n",
       "    single_eph_cell_size bare_nuclei  bland_chromatin  normal_nucleoli  \\\n",
       "0                      2           1                3                1   \n",
       "1                      7          10                3                2   \n",
       "2                      2           2                3                1   \n",
       "3                      3           4                3                7   \n",
       "4                      2           1                3                1   \n",
       "5                      7          10                9                7   \n",
       "6                      2          10                3                1   \n",
       "7                      2           1                3                1   \n",
       "8                      2           1                1                1   \n",
       "9                      2           1                2                1   \n",
       "10                     1           1                3                1   \n",
       "11                     2           1                2                1   \n",
       "12                     2           3                4                4   \n",
       "13                     2           3                3                1   \n",
       "14                     7           9                5                5   \n",
       "15                     6           1                4                3   \n",
       "16                     2           1                2                1   \n",
       "17                     2           1                3                1   \n",
       "18                     4          10                4                1   \n",
       "19                     2           1                3                1   \n",
       "\n",
       "    mitoses  class  \n",
       "0         1      2  \n",
       "1         1      2  \n",
       "2         1      2  \n",
       "3         1      2  \n",
       "4         1      2  \n",
       "5         1      4  \n",
       "6         1      2  \n",
       "7         1      2  \n",
       "8         5      2  \n",
       "9         1      2  \n",
       "10        1      2  \n",
       "11        1      2  \n",
       "12        1      4  \n",
       "13        1      2  \n",
       "14        4      4  \n",
       "15        1      4  \n",
       "16        1      2  \n",
       "17        1      2  \n",
       "18        2      4  \n",
       "19        1      2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvvbnFL36L85"
   },
   "source": [
    "We have to do some preprocessing on the data. We first pop the id column since it is of no use for our problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDeXwHdA5uUN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1000025\n",
       "1      1002945\n",
       "2      1015425\n",
       "3      1016277\n",
       "4      1017023\n",
       "        ...   \n",
       "694     776715\n",
       "695     841769\n",
       "696     888820\n",
       "697     897471\n",
       "698     897471\n",
       "Name: id, Length: 699, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubw5LueA6ZEY"
   },
   "source": [
    "Upon inspection of data, you can see that some values of the **bare_nuclei** column are unknown. We drop the rows with these unknown values. We also convert the **bare_nuclei** column to numeric. This is required for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCcOrl1ITVhr"
   },
   "outputs": [],
   "source": [
    "df = df[df[\"bare_nuclei\"] != '?' ]\n",
    "df.bare_nuclei = pd.to_numeric(df.bare_nuclei)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQMhcTQG7LzY"
   },
   "source": [
    "We check the class distribution of the data. You can see that there are two classes, 2.0 and 4.0\n",
    "According to the dataset:\n",
    "* **2.0 = benign**\n",
    "* **4.0 = malignant**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SaAdQrBv8daS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f62c984b550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['class'].hist(bins=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ENjMKvxQ6sWy"
   },
   "source": [
    "We are going to model this problem as a binary classification problem which detects whether the tumor is malignant or not. Hence, we change the dataset so that:\n",
    "* **benign(2.0) = 0**\n",
    "* **malignant(4.0) = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MVzeUwf_A3E",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df['class'] = np.where(df['class'] == 2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f62c968e290>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['class'].hist(bins=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EGbKO1bR8S9h"
   },
   "source": [
    "We then split the dataset into training and testing sets. Since the number of samples is small, we will perform validation on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUy7JcuAXjC"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>un_cell_size</th>\n",
       "      <th>un_cell_shape</th>\n",
       "      <th>marginal_adheshion</th>\n",
       "      <th>single_eph_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clump_thickness  un_cell_size  un_cell_shape  marginal_adheshion  \\\n",
       "576                5             1              1                   1   \n",
       "501                4             1              1                   1   \n",
       "114                3             3              2                   1   \n",
       "171                1             1              1                   1   \n",
       "371                1             1              3                   1   \n",
       "..               ...           ...            ...                 ...   \n",
       "57                 8             2              4                   1   \n",
       "14                 8             7              5                  10   \n",
       "662                1             1              3                   1   \n",
       "481                5             3              2                   4   \n",
       "536                5             1              1                   1   \n",
       "\n",
       "     single_eph_cell_size  bare_nuclei  bland_chromatin  normal_nucleoli  \\\n",
       "576                     2            1                2                1   \n",
       "501                     2            1                2                1   \n",
       "114                     2            3                3                1   \n",
       "171                     2            1                3                1   \n",
       "371                     2            1                1                1   \n",
       "..                    ...          ...              ...              ...   \n",
       "57                      5            1                5                4   \n",
       "14                      7            9                5                5   \n",
       "662                     2            1                2                1   \n",
       "481                     2            1                1                1   \n",
       "536                     2            1                3                1   \n",
       "\n",
       "     mitoses  \n",
       "576        1  \n",
       "501        1  \n",
       "114        1  \n",
       "171        1  \n",
       "371        1  \n",
       "..       ...  \n",
       "57         4  \n",
       "14         4  \n",
       "662        1  \n",
       "481        1  \n",
       "536        1  \n",
       "\n",
       "[546 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>un_cell_size</th>\n",
       "      <th>un_cell_shape</th>\n",
       "      <th>marginal_adheshion</th>\n",
       "      <th>single_eph_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clump_thickness  un_cell_size  un_cell_shape  marginal_adheshion  \\\n",
       "299                9             1              2                   6   \n",
       "450                4             1              1                   3   \n",
       "223                7             5              6                   3   \n",
       "676                1             1              2                   1   \n",
       "644                2             1              1                   1   \n",
       "..               ...           ...            ...                 ...   \n",
       "278                1             1              1                   1   \n",
       "56                 8            10             10                   1   \n",
       "25                 5             2              3                   4   \n",
       "674                1             1              1                   1   \n",
       "304                8             3              4                   9   \n",
       "\n",
       "     single_eph_cell_size  bare_nuclei  bland_chromatin  normal_nucleoli  \\\n",
       "299                     4           10                7                7   \n",
       "450                     1            1                2                1   \n",
       "223                     3            8                7                4   \n",
       "676                     2            1                2                1   \n",
       "644                     2            1                1                1   \n",
       "..                    ...          ...              ...              ...   \n",
       "278                     2            1                3                1   \n",
       "56                      3            6                3                9   \n",
       "25                      2            7                3                6   \n",
       "674                     2            1                2                1   \n",
       "304                     3           10                3                3   \n",
       "\n",
       "     mitoses  \n",
       "299        2  \n",
       "450        1  \n",
       "223        1  \n",
       "676        1  \n",
       "644        1  \n",
       "..       ...  \n",
       "278        1  \n",
       "56         1  \n",
       "25         1  \n",
       "674        1  \n",
       "304        1  \n",
       "\n",
       "[137 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_ZKokUP8kP3"
   },
   "source": [
    "We get the statistics for training. We can look at statistics to get an idea about the distribution of plots. If you need more visualization, you can create additional data plots. We will also be using the mean and standard deviation from statistics for normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k86tBT_QAm2P"
   },
   "outputs": [],
   "source": [
    "train_stats = train.describe()\n",
    "train_stats.pop('class')\n",
    "train_stats = train_stats.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>un_cell_size</th>\n",
       "      <th>un_cell_shape</th>\n",
       "      <th>marginal_adheshion</th>\n",
       "      <th>single_eph_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>546.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>546.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.529304</td>\n",
       "      <td>3.230769</td>\n",
       "      <td>3.265568</td>\n",
       "      <td>2.849817</td>\n",
       "      <td>3.305861</td>\n",
       "      <td>3.531136</td>\n",
       "      <td>3.479853</td>\n",
       "      <td>2.917582</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>0.358974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.806294</td>\n",
       "      <td>3.088577</td>\n",
       "      <td>2.991883</td>\n",
       "      <td>2.872101</td>\n",
       "      <td>2.277098</td>\n",
       "      <td>3.624577</td>\n",
       "      <td>2.494868</td>\n",
       "      <td>3.100545</td>\n",
       "      <td>1.793647</td>\n",
       "      <td>0.480140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clump_thickness  un_cell_size  un_cell_shape  marginal_adheshion  \\\n",
       "count       546.000000    546.000000     546.000000          546.000000   \n",
       "mean          4.529304      3.230769       3.265568            2.849817   \n",
       "std           2.806294      3.088577       2.991883            2.872101   \n",
       "min           1.000000      1.000000       1.000000            1.000000   \n",
       "25%           2.000000      1.000000       1.000000            1.000000   \n",
       "50%           4.000000      1.000000       1.500000            1.000000   \n",
       "75%           6.000000      5.000000       5.000000            4.000000   \n",
       "max          10.000000     10.000000      10.000000           10.000000   \n",
       "\n",
       "       single_eph_cell_size  bare_nuclei  bland_chromatin  normal_nucleoli  \\\n",
       "count            546.000000   546.000000       546.000000       546.000000   \n",
       "mean               3.305861     3.531136         3.479853         2.917582   \n",
       "std                2.277098     3.624577         2.494868         3.100545   \n",
       "min                1.000000     1.000000         1.000000         1.000000   \n",
       "25%                2.000000     1.000000         2.000000         1.000000   \n",
       "50%                2.000000     1.000000         3.000000         1.000000   \n",
       "75%                4.000000     5.750000         5.000000         4.000000   \n",
       "max               10.000000    10.000000        10.000000        10.000000   \n",
       "\n",
       "          mitoses       class  \n",
       "count  546.000000  546.000000  \n",
       "mean     1.642857    0.358974  \n",
       "std      1.793647    0.480140  \n",
       "min      1.000000    0.000000  \n",
       "25%      1.000000    0.000000  \n",
       "50%      1.000000    0.000000  \n",
       "75%      1.000000    1.000000  \n",
       "max     10.000000    1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clump_thickness</th>\n",
       "      <td>546.0</td>\n",
       "      <td>4.529304</td>\n",
       "      <td>2.806294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_cell_size</th>\n",
       "      <td>546.0</td>\n",
       "      <td>3.230769</td>\n",
       "      <td>3.088577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_cell_shape</th>\n",
       "      <td>546.0</td>\n",
       "      <td>3.265568</td>\n",
       "      <td>2.991883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marginal_adheshion</th>\n",
       "      <td>546.0</td>\n",
       "      <td>2.849817</td>\n",
       "      <td>2.872101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single_eph_cell_size</th>\n",
       "      <td>546.0</td>\n",
       "      <td>3.305861</td>\n",
       "      <td>2.277098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bare_nuclei</th>\n",
       "      <td>546.0</td>\n",
       "      <td>3.531136</td>\n",
       "      <td>3.624577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bland_chromatin</th>\n",
       "      <td>546.0</td>\n",
       "      <td>3.479853</td>\n",
       "      <td>2.494868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <td>546.0</td>\n",
       "      <td>2.917582</td>\n",
       "      <td>3.100545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitoses</th>\n",
       "      <td>546.0</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>1.793647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count      mean       std  min  25%  50%   75%   max\n",
       "clump_thickness       546.0  4.529304  2.806294  1.0  2.0  4.0  6.00  10.0\n",
       "un_cell_size          546.0  3.230769  3.088577  1.0  1.0  1.0  5.00  10.0\n",
       "un_cell_shape         546.0  3.265568  2.991883  1.0  1.0  1.5  5.00  10.0\n",
       "marginal_adheshion    546.0  2.849817  2.872101  1.0  1.0  1.0  4.00  10.0\n",
       "single_eph_cell_size  546.0  3.305861  2.277098  1.0  2.0  2.0  4.00  10.0\n",
       "bare_nuclei           546.0  3.531136  3.624577  1.0  1.0  1.0  5.75  10.0\n",
       "bland_chromatin       546.0  3.479853  2.494868  1.0  2.0  3.0  5.00  10.0\n",
       "normal_nucleoli       546.0  2.917582  3.100545  1.0  1.0  1.0  4.00  10.0\n",
       "mitoses               546.0  1.642857  1.793647  1.0  1.0  1.0  1.00  10.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8AJ0Crc8u9t"
   },
   "source": [
    "We pop the class column from the training and test sets to create train and test outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7EGUV-tA5LZ"
   },
   "outputs": [],
   "source": [
    "train_Y = train.pop(\"class\")\n",
    "test_Y = test.pop(\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576    0\n",
       "501    0\n",
       "114    0\n",
       "171    0\n",
       "371    0\n",
       "      ..\n",
       "57     1\n",
       "14     1\n",
       "662    0\n",
       "481    0\n",
       "536    0\n",
       "Name: class, Length: 546, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299    1\n",
       "450    0\n",
       "223    1\n",
       "676    0\n",
       "644    0\n",
       "      ..\n",
       "278    0\n",
       "56     1\n",
       "25     1\n",
       "674    0\n",
       "304    1\n",
       "Name: class, Length: 137, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9wVRO5E9AgA"
   },
   "source": [
    "Here we normalize the data by using the formula: **X = (X - mean(X)) / StandardDeviation(X)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 9)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats['mean'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats['std'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_vec_x = np.array(range(1, 10))\n",
    "test_vec_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>un_cell_size</th>\n",
       "      <th>un_cell_shape</th>\n",
       "      <th>marginal_adheshion</th>\n",
       "      <th>single_eph_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clump_thickness  un_cell_size  un_cell_shape  marginal_adheshion  \\\n",
       "576                5             1              1                   1   \n",
       "501                4             1              1                   1   \n",
       "114                3             3              2                   1   \n",
       "171                1             1              1                   1   \n",
       "371                1             1              3                   1   \n",
       "..               ...           ...            ...                 ...   \n",
       "57                 8             2              4                   1   \n",
       "14                 8             7              5                  10   \n",
       "662                1             1              3                   1   \n",
       "481                5             3              2                   4   \n",
       "536                5             1              1                   1   \n",
       "\n",
       "     single_eph_cell_size  bare_nuclei  bland_chromatin  normal_nucleoli  \\\n",
       "576                     2            1                2                1   \n",
       "501                     2            1                2                1   \n",
       "114                     2            3                3                1   \n",
       "171                     2            1                3                1   \n",
       "371                     2            1                1                1   \n",
       "..                    ...          ...              ...              ...   \n",
       "57                      5            1                5                4   \n",
       "14                      7            9                5                5   \n",
       "662                     2            1                2                1   \n",
       "481                     2            1                1                1   \n",
       "536                     2            1                3                1   \n",
       "\n",
       "     mitoses  \n",
       "576        1  \n",
       "501        1  \n",
       "114        1  \n",
       "171        1  \n",
       "371        1  \n",
       "..       ...  \n",
       "57         4  \n",
       "14         4  \n",
       "662        1  \n",
       "481        1  \n",
       "536        1  \n",
       "\n",
       "[546 rows x 9 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clump_thickness         5\n",
       "un_cell_size            1\n",
       "un_cell_shape           1\n",
       "marginal_adheshion      1\n",
       "single_eph_cell_size    2\n",
       "bare_nuclei             1\n",
       "bland_chromatin         2\n",
       "normal_nucleoli         1\n",
       "mitoses                 1\n",
       "Name: 576, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>un_cell_size</th>\n",
       "      <th>un_cell_shape</th>\n",
       "      <th>marginal_adheshion</th>\n",
       "      <th>single_eph_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-7</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-7</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-7</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-4</td>\n",
       "      <td>-7</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-6</td>\n",
       "      <td>-7</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-7</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-6</td>\n",
       "      <td>-7</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-4</td>\n",
       "      <td>-7</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clump_thickness  un_cell_size  un_cell_shape  marginal_adheshion  \\\n",
       "576                4            -1             -2                  -3   \n",
       "501                3            -1             -2                  -3   \n",
       "114                2             1             -1                  -3   \n",
       "171                0            -1             -2                  -3   \n",
       "371                0            -1              0                  -3   \n",
       "..               ...           ...            ...                 ...   \n",
       "57                 7             0              1                  -3   \n",
       "14                 7             5              2                   6   \n",
       "662                0            -1              0                  -3   \n",
       "481                4             1             -1                   0   \n",
       "536                4            -1             -2                  -3   \n",
       "\n",
       "     single_eph_cell_size  bare_nuclei  bland_chromatin  normal_nucleoli  \\\n",
       "576                    -3           -5               -5               -7   \n",
       "501                    -3           -5               -5               -7   \n",
       "114                    -3           -3               -4               -7   \n",
       "171                    -3           -5               -4               -7   \n",
       "371                    -3           -5               -6               -7   \n",
       "..                    ...          ...              ...              ...   \n",
       "57                      0           -5               -2               -4   \n",
       "14                      2            3               -2               -3   \n",
       "662                    -3           -5               -5               -7   \n",
       "481                    -3           -5               -6               -7   \n",
       "536                    -3           -5               -4               -7   \n",
       "\n",
       "     mitoses  \n",
       "576       -8  \n",
       "501       -8  \n",
       "114       -8  \n",
       "171       -8  \n",
       "371       -8  \n",
       "..       ...  \n",
       "57        -5  \n",
       "14        -5  \n",
       "662       -8  \n",
       "481       -8  \n",
       "536       -8  \n",
       "\n",
       "[546 rows x 9 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train-test_vec_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clump_thickness         4\n",
       "un_cell_size           -1\n",
       "un_cell_shape          -2\n",
       "marginal_adheshion     -3\n",
       "single_eph_cell_size   -3\n",
       "bare_nuclei            -5\n",
       "bland_chromatin        -5\n",
       "normal_nucleoli        -7\n",
       "mitoses                -8\n",
       "Name: 576, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train-test_vec_x).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>un_cell_size</th>\n",
       "      <th>un_cell_shape</th>\n",
       "      <th>marginal_adheshion</th>\n",
       "      <th>single_eph_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clump_thickness  un_cell_size  un_cell_shape  marginal_adheshion  \\\n",
       "576              5.0           0.5       0.333333                0.25   \n",
       "501              4.0           0.5       0.333333                0.25   \n",
       "114              3.0           1.5       0.666667                0.25   \n",
       "171              1.0           0.5       0.333333                0.25   \n",
       "371              1.0           0.5       1.000000                0.25   \n",
       "..               ...           ...            ...                 ...   \n",
       "57               8.0           1.0       1.333333                0.25   \n",
       "14               8.0           3.5       1.666667                2.50   \n",
       "662              1.0           0.5       1.000000                0.25   \n",
       "481              5.0           1.5       0.666667                1.00   \n",
       "536              5.0           0.5       0.333333                0.25   \n",
       "\n",
       "     single_eph_cell_size  bare_nuclei  bland_chromatin  normal_nucleoli  \\\n",
       "576                   0.4     0.166667         0.285714            0.125   \n",
       "501                   0.4     0.166667         0.285714            0.125   \n",
       "114                   0.4     0.500000         0.428571            0.125   \n",
       "171                   0.4     0.166667         0.428571            0.125   \n",
       "371                   0.4     0.166667         0.142857            0.125   \n",
       "..                    ...          ...              ...              ...   \n",
       "57                    1.0     0.166667         0.714286            0.500   \n",
       "14                    1.4     1.500000         0.714286            0.625   \n",
       "662                   0.4     0.166667         0.285714            0.125   \n",
       "481                   0.4     0.166667         0.142857            0.125   \n",
       "536                   0.4     0.166667         0.428571            0.125   \n",
       "\n",
       "      mitoses  \n",
       "576  0.111111  \n",
       "501  0.111111  \n",
       "114  0.111111  \n",
       "171  0.111111  \n",
       "371  0.111111  \n",
       "..        ...  \n",
       "57   0.444444  \n",
       "14   0.444444  \n",
       "662  0.111111  \n",
       "481  0.111111  \n",
       "536  0.111111  \n",
       "\n",
       "[546 rows x 9 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train/test_vec_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clump_thickness         4.529304\n",
       "un_cell_size            3.230769\n",
       "un_cell_shape           3.265568\n",
       "marginal_adheshion      2.849817\n",
       "single_eph_cell_size    3.305861\n",
       "bare_nuclei             3.531136\n",
       "bland_chromatin         3.479853\n",
       "normal_nucleoli         2.917582\n",
       "mitoses                 1.642857\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDo__q_AA3j0"
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdARlWaDA_8G"
   },
   "outputs": [],
   "source": [
    "norm_train_X = norm(train)\n",
    "norm_test_X = norm(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16772867, -0.72226439, -0.75723814, ..., -0.59315914,\n",
       "        -0.61846627, -0.35840787],\n",
       "       [-0.18861317, -0.72226439, -0.75723814, ..., -0.59315914,\n",
       "        -0.61846627, -0.35840787],\n",
       "       [-0.54495501, -0.07471701, -0.42300045, ..., -0.19233626,\n",
       "        -0.61846627, -0.35840787],\n",
       "       ...,\n",
       "       [-1.25763869, -0.72226439, -0.08876276, ..., -0.59315914,\n",
       "        -0.61846627, -0.35840787],\n",
       "       [ 0.16772867, -0.07471701, -0.42300045, ..., -0.99398202,\n",
       "        -0.61846627, -0.35840787],\n",
       "       [ 0.16772867, -0.72226439, -0.75723814, ..., -0.19233626,\n",
       "        -0.61846627, -0.35840787]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train_X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6LIVZbj9Usv"
   },
   "source": [
    "We now create Tensorflow datasets for training and test sets to easily be able to build and manage an input pipeline for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 9)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train_X.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1S0RtsP1Xsj8"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((norm_train_X.values, train_Y.values))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((norm_test_X.values, test_Y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Nb44PpV9hR4"
   },
   "source": [
    "We shuffle and prepare a batched dataset to be used for training in our custom training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9qdsNPen5-F"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train)).batch(batch_size)\n",
    "\n",
    "test_dataset =  test_dataset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 9)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataset.take(1):\n",
    "    print(f\"{x[0].shape}\")\n",
    "    print(f\"{x[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "a = enumerate(train_dataset)\n",
    "\n",
    "print(len(list(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GcbOJ6C79qT5"
   },
   "source": [
    "## Define the Model\n",
    "\n",
    "Now we will define the model. Here, we use the Keras Functional API to create a simple network of two `Dense` layers. We have modelled the problem as a binary classification problem and hence we add a single layer with sigmoid activation as the final layer of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HU3qcM9WBcMh"
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    inputs = tf.keras.layers.Input(shape=(len(train.columns)))\n",
    "\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "model = base_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBhKIcKQ-Bwe"
   },
   "source": [
    "## Define Optimizer and Loss\n",
    "\n",
    "We use RMSprop optimizer and binary crossentropy as our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5B3vh6fs84i"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSNDewgovSZ8"
   },
   "source": [
    "## Evaluate Untrained Model\n",
    "We calculate the loss on the model before training begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 9)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_test_X.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUScS3GbtPXt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before training 0.6863\n"
     ]
    }
   ],
   "source": [
    "outputs = model(norm_test_X.values)\n",
    "loss_value = loss_object(y_true=test_Y.values, y_pred=outputs)\n",
    "print(\"Loss before training %.4f\" % loss_value.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPPb5ewkzMBY"
   },
   "source": [
    "We also plot the confusion matrix to visualize the true outputs against the outputs predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ueenYwWZvQM_"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title='', labels=[0,1]):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title(title)\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "          plt.text(j, i, format(cm[i, j], fmt),\n",
    "                  horizontalalignment=\"center\",\n",
    "                  color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FApnBUNWv-ZR"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(test_Y.values, tf.round(outputs), title='Confusion Matrix for Untrained Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-HTkbQb-gYp"
   },
   "source": [
    "## Define Metrics (Please complete this section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AYUyRka1-j87"
   },
   "source": [
    "### Define Custom F1Score Metric\n",
    "In this example, we will define a custom F1Score metric using the formula. \n",
    "\n",
    "**F1 Score = 2 * ((precision * recall) / (precision + recall))**\n",
    "\n",
    "**precision = true_positives / (true_positives + false_positives)**\n",
    "\n",
    "**recall = true_positives / (true_positives + false_negatives)**\n",
    "\n",
    "We use `confusion_matrix` defined in `tf.math` to calculate precision and recall.\n",
    "\n",
    "Here you can see that we have subclassed `tf.keras.Metric` and implemented the three required methods `update_state`, `result` and `reset_states`.\n",
    "\n",
    "### Please complete the result() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PdUe6cqvbzXy"
   },
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        '''initializes attributes of the class'''\n",
    "        \n",
    "        # call the parent class init\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # Initialize Required variables\n",
    "        # true positives\n",
    "        self.tp = tf.Variable(0, dtype = 'int32')\n",
    "        # false positives\n",
    "        self.fp = tf.Variable(0, dtype = 'int32')\n",
    "        # true negatives\n",
    "        self.tn = tf.Variable(0, dtype = 'int32')\n",
    "        # false negatives\n",
    "        self.fn = tf.Variable(0, dtype = 'int32')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        '''\n",
    "        Accumulates statistics for the metric\n",
    "        \n",
    "        Args:\n",
    "            y_true: target values from the test data\n",
    "            y_pred: predicted values by the model\n",
    "        '''\n",
    "\n",
    "        # Calulcate confusion matrix.\n",
    "        conf_matrix = tf.math.confusion_matrix(y_true, y_pred, num_classes=2)\n",
    "        \n",
    "        # Update values of true positives, true negatives, false positives and false negatives from confusion matrix.\n",
    "        self.tn.assign_add(conf_matrix[0][0])\n",
    "        self.tp.assign_add(conf_matrix[1][1])\n",
    "        self.fp.assign_add(conf_matrix[0][1])\n",
    "        self.fn.assign_add(conf_matrix[1][0])\n",
    "\n",
    "    def result(self):\n",
    "        '''Computes and returns the metric value tensor.'''\n",
    "\n",
    "        # Calculate precision\n",
    "        if (self.tp + self.fp == 0):\n",
    "            precision = 1.0\n",
    "        else:\n",
    "            precision = self.tp / (self.tp + self.fp)\n",
    "      \n",
    "        # Calculate recall\n",
    "        if (self.tp + self.fn == 0):\n",
    "            recall = 1.0\n",
    "        else:\n",
    "            recall = self.tp / (self.tp + self.fn)\n",
    "\n",
    "        # Return F1 Score\n",
    "        ### START CODE HERE ###\n",
    "        f1_score =  2 * ((precision * recall) / (precision + recall))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return f1_score\n",
    "\n",
    "    def reset_states(self):\n",
    "        '''Resets all of the metric state variables.'''\n",
    "        \n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.tp.assign(0)\n",
    "        self.tn.assign(0) \n",
    "        self.fp.assign(0)\n",
    "        self.fn.assign(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.2222222222222222>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Code:\n",
    "\n",
    "test_F1Score = F1Score()\n",
    "\n",
    "test_F1Score.tp = tf.Variable(2, dtype = 'int32')\n",
    "test_F1Score.fp = tf.Variable(5, dtype = 'int32')\n",
    "test_F1Score.tn = tf.Variable(7, dtype = 'int32')\n",
    "test_F1Score.fn = tf.Variable(9, dtype = 'int32')\n",
    "test_F1Score.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```txt\n",
    "<tf.Tensor: shape=(), dtype=float64, numpy=0.2222222222222222>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xiTa2CePAOTa"
   },
   "source": [
    "We initialize the seprate metrics required for training and validation. In addition to our custom F1Score metric, we are also using `BinaryAccuracy` defined in `tf.keras.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Pa_x-5-CH_V"
   },
   "outputs": [],
   "source": [
    "train_f1score_metric = F1Score()\n",
    "val_f1score_metric = F1Score()\n",
    "\n",
    "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1huOxRpEAxvf"
   },
   "source": [
    "## Apply Gradients (Please complete this section)\n",
    "\n",
    "The core of training is using the model to calculate the logits on specific set of inputs and compute the loss(in this case **binary crossentropy**) by comparing the predicted outputs to the true outputs. We then update the trainable weights using the optimizer algorithm chosen. The optimizer algorithm requires our computed loss and partial derivatives of loss with respect to each of the trainable weights to make updates to the same.\n",
    "\n",
    "We use gradient tape to calculate the gradients and then update the model trainable weights using the optimizer.\n",
    "\n",
    "### Please complete the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMPe25Dstn0v"
   },
   "outputs": [],
   "source": [
    "def apply_gradient(optimizer, loss_object, model, x, y):\n",
    "    '''\n",
    "    applies the gradients to the trainable model weights\n",
    "    \n",
    "    Args:\n",
    "        optimizer: optimizer to update model weights\n",
    "        loss_object: type of loss to measure during training\n",
    "        model: the model we are training\n",
    "        x: input data to the model\n",
    "        y: target values for each input\n",
    "    '''\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "    ### START CODE HERE ###\n",
    "        #print(f\"x.shape = {x.shape}\")\n",
    "        #print(f\"type(x) = {type(x)}\")\n",
    "        logits = model(x)\n",
    "        loss_value = loss_object(y_true=y, y_pred=logits)\n",
    "  \n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    ### END CODE HERE ###\n",
    "  \n",
    "    return logits, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50690997]\n",
      " [0.54847735]\n",
      " [0.47968623]\n",
      " [0.54630774]\n",
      " [0.5405842 ]\n",
      " [0.4779669 ]\n",
      " [0.49051824]\n",
      " [0.548072  ]]\n",
      "0.7150524\n"
     ]
    }
   ],
   "source": [
    "# Test Code:\n",
    "\n",
    "test_model = tf.keras.models.load_model('./test_model')\n",
    "test_logits, test_loss = apply_gradient(optimizer, loss_object, test_model, norm_test_X.values, test_Y.values)\n",
    "\n",
    "print(test_logits.numpy()[:8])\n",
    "print(test_loss.numpy())\n",
    "\n",
    "del test_model\n",
    "del test_logits\n",
    "del test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "The output will be close to these values:\n",
    "```txt\n",
    "[[0.5516499 ]\n",
    " [0.52124363]\n",
    " [0.5412698 ]\n",
    " [0.54203206]\n",
    " [0.50022954]\n",
    " [0.5459626 ]\n",
    " [0.47841492]\n",
    " [0.54381996]]\n",
    "0.7030578\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYM6GZPjB40r"
   },
   "source": [
    "## Training Loop (Please complete this section)\n",
    "\n",
    "This function performs training during one epoch. We run through all batches of training data in each epoch to make updates to trainable weights using our previous function.\n",
    "You can see that we also call `update_state` on our metrics to accumulate the value of our metrics. \n",
    "\n",
    "We are displaying a progress bar to indicate completion of training in each epoch. Here we use `tqdm` for displaying the progress bar. \n",
    "\n",
    "### Please complete the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 9), dtype=float64, numpy=\n",
      "array([[-0.54495501, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.54495501, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.18861317, -0.72226439, -0.75723814, -0.64406403, -1.01263122,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-1.25763869, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-0.18861317, -0.3984907 , -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.54495501, -0.3984907 , -0.42300045, -0.64406403,  0.30483497,\n",
      "        -0.14653723, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.54495501,  0.24905668,  0.57971263,  0.05229035,  1.62230116,\n",
      "        -0.14653723,  0.20848663,  0.99415352, -0.35840787],\n",
      "       [ 0.16772867, -0.3984907 , -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.42243147, -0.19233626,  0.02658164, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.07471701,  0.57971263,  0.74864473, -0.13432042,\n",
      "        -0.14653723,  0.20848663,  2.28424936, -0.35840787],\n",
      "       [-0.18861317, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.14653723, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.54495501, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-1.25763869, -0.72226439, -0.75723814, -0.29588684, -1.01263122,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [ 1.94943787,  1.22037776,  1.24818801,  1.09682192,  0.30483497,\n",
      "         1.78472243,  0.20848663, -0.61846627,  0.19911548],\n",
      "       [-1.25763869, -0.72226439, -0.75723814,  0.05229035, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 1.94943787,  0.24905668, -0.08876276,  2.48953067, -0.13432042,\n",
      "         1.78472243,  1.41095528, -0.61846627,  0.19911548],\n",
      "       [-0.90129685, -0.72226439, -0.75723814, -0.29588684, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 1.23675419,  2.19169883,  2.25090108,  2.48953067,  1.18314577,\n",
      "         1.78472243,  2.61342393,  2.28424936, -0.35840787],\n",
      "       [ 0.52407051,  1.54415145,  1.5824257 , -0.64406403, -0.13432042,\n",
      "         0.129357  , -0.19233626,  1.31667748, -0.35840787],\n",
      "       [ 0.16772867, -0.3984907 , -0.42300045, -0.29588684, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.29594231, -0.35840787],\n",
      "       [ 0.16772867, -0.3984907 , -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-0.18861317, -0.72226439, -0.75723814, -0.64406403, -1.01263122,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [ 1.23675419,  2.19169883,  0.57971263,  0.05229035,  2.06145656,\n",
      "         0.129357  ,  0.20848663,  2.28424936,  0.75663883],\n",
      "       [ 1.23675419, -0.3984907 ,  0.24547493, -0.64406403,  0.74399037,\n",
      "        -0.69832571,  0.60930951,  0.3491056 ,  1.31416217],\n",
      "       [-1.25763869, -0.72226439, -0.75723814, -0.64406403, -1.01263122,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-0.90129685, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-0.18861317, -0.72226439, -0.75723814, -0.29588684, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-1.25763869, -0.72226439, -0.75723814, -0.64406403, -1.01263122,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787]])>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0])>)\n",
      "True\n",
      "(32, 9)\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(32, 9), dtype=float64, numpy=\n",
      "array([[-0.54495501, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.54495501, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.18861317, -0.72226439, -0.75723814, -0.64406403, -1.01263122,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-1.25763869, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-0.18861317, -0.3984907 , -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.54495501, -0.3984907 , -0.42300045, -0.64406403,  0.30483497,\n",
      "        -0.14653723, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.54495501,  0.24905668,  0.57971263,  0.05229035,  1.62230116,\n",
      "        -0.14653723,  0.20848663,  0.99415352, -0.35840787],\n",
      "       [ 0.16772867, -0.3984907 , -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.42243147, -0.19233626,  0.02658164, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.07471701,  0.57971263,  0.74864473, -0.13432042,\n",
      "        -0.14653723,  0.20848663,  2.28424936, -0.35840787],\n",
      "       [-0.18861317, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.14653723, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-0.54495501, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-1.25763869, -0.72226439, -0.75723814, -0.29588684, -1.01263122,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [ 1.94943787,  1.22037776,  1.24818801,  1.09682192,  0.30483497,\n",
      "         1.78472243,  0.20848663, -0.61846627,  0.19911548],\n",
      "       [-1.25763869, -0.72226439, -0.75723814,  0.05229035, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 0.16772867, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 1.94943787,  0.24905668, -0.08876276,  2.48953067, -0.13432042,\n",
      "         1.78472243,  1.41095528, -0.61846627,  0.19911548],\n",
      "       [-0.90129685, -0.72226439, -0.75723814, -0.29588684, -0.57347582,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787],\n",
      "       [ 1.23675419,  2.19169883,  2.25090108,  2.48953067,  1.18314577,\n",
      "         1.78472243,  2.61342393,  2.28424936, -0.35840787],\n",
      "       [ 0.52407051,  1.54415145,  1.5824257 , -0.64406403, -0.13432042,\n",
      "         0.129357  , -0.19233626,  1.31667748, -0.35840787],\n",
      "       [ 0.16772867, -0.3984907 , -0.42300045, -0.29588684, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.29594231, -0.35840787],\n",
      "       [ 0.16772867, -0.3984907 , -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-0.18861317, -0.72226439, -0.75723814, -0.64406403, -1.01263122,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [ 1.23675419,  2.19169883,  0.57971263,  0.05229035,  2.06145656,\n",
      "         0.129357  ,  0.20848663,  2.28424936,  0.75663883],\n",
      "       [ 1.23675419, -0.3984907 ,  0.24547493, -0.64406403,  0.74399037,\n",
      "        -0.69832571,  0.60930951,  0.3491056 ,  1.31416217],\n",
      "       [-1.25763869, -0.72226439, -0.75723814, -0.64406403, -1.01263122,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-0.90129685, -0.72226439, -0.75723814, -0.64406403, -0.57347582,\n",
      "        -0.69832571, -0.99398202, -0.61846627, -0.35840787],\n",
      "       [-0.18861317, -0.72226439, -0.75723814, -0.29588684, -0.57347582,\n",
      "        -0.69832571, -0.59315914, -0.61846627, -0.35840787],\n",
      "       [-1.25763869, -0.72226439, -0.75723814, -0.64406403, -1.01263122,\n",
      "        -0.69832571, -0.19233626, -0.61846627, -0.35840787]])>>\n",
      "--------------\n",
      "True\n",
      "(32,)\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0])>>\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for element in train_dataset.take(1):\n",
    "    #print(f\"{x.shape}\")\n",
    "    #print(f\"{type(x)}\")\n",
    "    #print(f\"{x.numpy().shape}\")\n",
    "    print(f\"{element}\")\n",
    "    for in_ele in element:\n",
    "        print(f\"{tf.is_tensor(in_ele)}\")\n",
    "        print(f\"{in_ele.shape}\")\n",
    "        print(f\"{in_ele.numpy}\")\n",
    "        print(f\"--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fHoh_hgz2PC"
   },
   "outputs": [],
   "source": [
    "def train_data_for_one_epoch(train_dataset, optimizer, loss_object, model, \n",
    "                             train_acc_metric, train_f1score_metric, verbose=True):\n",
    "    '''\n",
    "    Computes the loss then updates the weights and metrics for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        train_dataset: the training dataset\n",
    "        optimizer: optimizer to update model weights\n",
    "        loss_object: type of loss to measure during training\n",
    "        model: the model we are training\n",
    "        train_acc_metric: calculates how often predictions match labels\n",
    "        train_f1score_metric: custom metric we defined earlier\n",
    "    '''\n",
    "    losses = []\n",
    "\n",
    "    #Iterate through all batches of training data\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "        #Calculate loss and update trainable variables using optimizer\n",
    "        ### START CODE HERE ###\n",
    "        logits, loss_value = apply_gradient(optimizer, loss_object, model, x_batch_train, y_batch_train)\n",
    "        losses.append(loss_value)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        #Round off logits to nearest integer and cast to integer for calulating metrics\n",
    "        logits = tf.round(logits)\n",
    "        logits = tf.cast(logits, 'int64')\n",
    "\n",
    "        #Update the training metrics\n",
    "        ### START CODE HERE ###\n",
    "        train_acc_metric.update_state(y_true=y_batch_train, y_pred=logits)\n",
    "        train_f1score_metric.update_state(y_true=y_batch_train, y_pred=logits)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        #Update progress\n",
    "        if verbose:\n",
    "            print(\"Training loss for step %s: %.4f\" % (int(step), float(loss_value)))\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75278926\n",
      "0.6194535\n",
      "0.5812181\n",
      "0.48754328\n",
      "0.4111054\n",
      "0.35354084\n",
      "0.406034\n",
      "0.38272473\n",
      "0.3757897\n",
      "0.3653785\n",
      "0.33351868\n",
      "0.28029466\n",
      "0.24957472\n",
      "0.2108225\n",
      "0.22411086\n",
      "0.17001396\n",
      "0.20693162\n",
      "0.17743173\n"
     ]
    }
   ],
   "source": [
    "# TEST CODE\n",
    "\n",
    "test_model = tf.keras.models.load_model('./test_model')\n",
    "\n",
    "test_losses = train_data_for_one_epoch(train_dataset, optimizer, loss_object, test_model, \n",
    "                             train_acc_metric, train_f1score_metric, verbose=False)\n",
    "\n",
    "for test_loss in test_losses:\n",
    "    print(test_loss.numpy())\n",
    "\n",
    "del test_model\n",
    "del test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "The losses should generally be decreasing and will start from around 0.75. For example:\n",
    "\n",
    "```\n",
    "0.7600615\n",
    "0.6092045\n",
    "0.5525634\n",
    "0.4358902\n",
    "0.4765755\n",
    "0.43327087\n",
    "0.40585428\n",
    "0.32855004\n",
    "0.35755336\n",
    "0.3651728\n",
    "0.33971977\n",
    "0.27372319\n",
    "0.25026917\n",
    "0.29229593\n",
    "0.242178\n",
    "0.20602849\n",
    "0.15887335\n",
    "0.090397514\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9RJq8BLCsSF"
   },
   "source": [
    "At the end of each epoch, we have to validate the model on the test dataset. The following function calculates the loss on test dataset and updates the states of the validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gLJyAJE0YRc"
   },
   "outputs": [],
   "source": [
    "def perform_validation():\n",
    "    losses = []\n",
    "\n",
    "    #Iterate through all batches of validation data.\n",
    "    for x_val, y_val in test_dataset:\n",
    "\n",
    "        #Calculate validation loss for current batch.\n",
    "        val_logits = model(x_val) \n",
    "        val_loss = loss_object(y_true=y_val, y_pred=val_logits)\n",
    "        losses.append(val_loss)\n",
    "\n",
    "        #Round off and cast outputs to either  or 1\n",
    "        val_logits = tf.cast(tf.round(model(x_val)), 'int64')\n",
    "\n",
    "        #Update validation metrics\n",
    "        val_acc_metric.update_state(y_val, val_logits)\n",
    "        val_f1score_metric.update_state(y_val, val_logits)\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLymSCkUC-CL"
   },
   "source": [
    "Next we define the training loop that runs through the training samples repeatedly over a fixed number of epochs. Here we combine the functions we built earlier to establish the following flow:\n",
    "1. Perform training over all batches of training data.\n",
    "2. Get values of metrics.\n",
    "3. Perform validation to calculate loss and update validation metrics on test data.\n",
    "4. Reset the metrics at the end of epoch.\n",
    "5. Display statistics at the end of each epoch.\n",
    "\n",
    "**Note** : We also calculate the training and validation losses for the whole epoch at the end of the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOO1x3VyuPUV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "Training loss for step 0: 0.6770\n",
      "Training loss for step 1: 0.5259\n",
      "Training loss for step 2: 0.4575\n",
      "Training loss for step 3: 0.3771\n",
      "Training loss for step 4: 0.3626\n",
      "Training loss for step 5: 0.3180\n",
      "Training loss for step 6: 0.2654\n",
      "Training loss for step 7: 0.3105\n",
      "Training loss for step 8: 0.2523\n",
      "Training loss for step 9: 0.2293\n",
      "Training loss for step 10: 0.2789\n",
      "Training loss for step 11: 0.2607\n",
      "Training loss for step 12: 0.2196\n",
      "Training loss for step 13: 0.2481\n",
      "Training loss for step 14: 0.1068\n",
      "Training loss for step 15: 0.2112\n",
      "Training loss for step 16: 0.1106\n",
      "Training loss for step 17: 0.1414\n",
      "\n",
      " Epcoh 0: Train loss: 0.2974  Validation Loss: 0.1171, Train Accuracy: 0.9300, Validation Accuracy 0.9937, Train F1 Score: 0.9022, Validation F1 Score: 0.9882\n",
      "Start of epoch 1\n",
      "Training loss for step 0: 0.1757\n",
      "Training loss for step 1: 0.1387\n",
      "Training loss for step 2: 0.1071\n",
      "Training loss for step 3: 0.1320\n",
      "Training loss for step 4: 0.0810\n",
      "Training loss for step 5: 0.1055\n",
      "Training loss for step 6: 0.0684\n",
      "Training loss for step 7: 0.2041\n",
      "Training loss for step 8: 0.1314\n",
      "Training loss for step 9: 0.2194\n",
      "Training loss for step 10: 0.0896\n",
      "Training loss for step 11: 0.1211\n",
      "Training loss for step 12: 0.0931\n",
      "Training loss for step 13: 0.1157\n",
      "Training loss for step 14: 0.0424\n",
      "Training loss for step 15: 0.0488\n",
      "Training loss for step 16: 0.1507\n",
      "Training loss for step 17: 0.0162\n",
      "\n",
      " Epcoh 1: Train loss: 0.1134  Validation Loss: 0.0544, Train Accuracy: 0.9705, Validation Accuracy 0.9937, Train F1 Score: 0.9572, Validation F1 Score: 0.9882\n",
      "Start of epoch 2\n",
      "Training loss for step 0: 0.0698\n",
      "Training loss for step 1: 0.1562\n",
      "Training loss for step 2: 0.1179\n",
      "Training loss for step 3: 0.0556\n",
      "Training loss for step 4: 0.1727\n",
      "Training loss for step 5: 0.0407\n",
      "Training loss for step 6: 0.0339\n",
      "Training loss for step 7: 0.0758\n",
      "Training loss for step 8: 0.0534\n",
      "Training loss for step 9: 0.1116\n",
      "Training loss for step 10: 0.0530\n",
      "Training loss for step 11: 0.0792\n",
      "Training loss for step 12: 0.1272\n",
      "Training loss for step 13: 0.1714\n",
      "Training loss for step 14: 0.0183\n",
      "Training loss for step 15: 0.1279\n",
      "Training loss for step 16: 0.1110\n",
      "Training loss for step 17: 0.1334\n",
      "\n",
      " Epcoh 2: Train loss: 0.0949  Validation Loss: 0.0371, Train Accuracy: 0.9688, Validation Accuracy 0.9937, Train F1 Score: 0.9548, Validation F1 Score: 0.9882\n",
      "Start of epoch 3\n",
      "Training loss for step 0: 0.0183\n",
      "Training loss for step 1: 0.0994\n",
      "Training loss for step 2: 0.0159\n",
      "Training loss for step 3: 0.0908\n",
      "Training loss for step 4: 0.0313\n",
      "Training loss for step 5: 0.0643\n",
      "Training loss for step 6: 0.3101\n",
      "Training loss for step 7: 0.1268\n",
      "Training loss for step 8: 0.2224\n",
      "Training loss for step 9: 0.0639\n",
      "Training loss for step 10: 0.0201\n",
      "Training loss for step 11: 0.0255\n",
      "Training loss for step 12: 0.0447\n",
      "Training loss for step 13: 0.0793\n",
      "Training loss for step 14: 0.0284\n",
      "Training loss for step 15: 0.1139\n",
      "Training loss for step 16: 0.0776\n",
      "Training loss for step 17: 0.0377\n",
      "\n",
      " Epcoh 3: Train loss: 0.0817  Validation Loss: 0.0288, Train Accuracy: 0.9705, Validation Accuracy 0.9937, Train F1 Score: 0.9572, Validation F1 Score: 0.9882\n",
      "Start of epoch 4\n",
      "Training loss for step 0: 0.0209\n",
      "Training loss for step 1: 0.0095\n",
      "Training loss for step 2: 0.0100\n",
      "Training loss for step 3: 0.1342\n",
      "Training loss for step 4: 0.0692\n",
      "Training loss for step 5: 0.1310\n",
      "Training loss for step 6: 0.0375\n",
      "Training loss for step 7: 0.0681\n",
      "Training loss for step 8: 0.1696\n",
      "Training loss for step 9: 0.1671\n",
      "Training loss for step 10: 0.0162\n",
      "Training loss for step 11: 0.0780\n",
      "Training loss for step 12: 0.0316\n",
      "Training loss for step 13: 0.0436\n",
      "Training loss for step 14: 0.0793\n",
      "Training loss for step 15: 0.0637\n",
      "Training loss for step 16: 0.2494\n",
      "Training loss for step 17: 0.0338\n",
      "\n",
      " Epcoh 4: Train loss: 0.0785  Validation Loss: 0.0277, Train Accuracy: 0.9740, Validation Accuracy 0.9937, Train F1 Score: 0.9624, Validation F1 Score: 0.9882\n"
     ]
    }
   ],
   "source": [
    "# Iterate over epochs.\n",
    "epochs = 5\n",
    "epochs_val_losses, epochs_train_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "    #Perform Training over all batches of train data\n",
    "    losses_train = train_data_for_one_epoch(train_dataset, optimizer, loss_object, model, train_acc_metric, train_f1score_metric)\n",
    "\n",
    "    # Get results from training metrics\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_f1score = train_f1score_metric.result()\n",
    "\n",
    "    #Perform validation on all batches of test data\n",
    "    losses_val = perform_validation()\n",
    "\n",
    "    # Get results from validation metrics\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_f1score = val_f1score_metric.result()\n",
    "\n",
    "    #Calculate training and validation losses for current epoch\n",
    "    losses_train_mean = np.mean(losses_train)\n",
    "    losses_val_mean = np.mean(losses_val)\n",
    "    epochs_val_losses.append(losses_val_mean)\n",
    "    epochs_train_losses.append(losses_train_mean)\n",
    "\n",
    "    print('\\n Epcoh %s: Train loss: %.4f  Validation Loss: %.4f, Train Accuracy: %.4f, Validation Accuracy %.4f, Train F1 Score: %.4f, Validation F1 Score: %.4f' % (epoch, float(losses_train_mean), float(losses_val_mean), float(train_acc), float(val_acc), train_f1score, val_f1score))\n",
    "\n",
    "    #Reset states of all metrics\n",
    "    train_acc_metric.reset_states()\n",
    "    val_acc_metric.reset_states()\n",
    "    val_f1score_metric.reset_states()\n",
    "    train_f1score_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoLxueMdzm14"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EGW3HVUzqBX"
   },
   "source": [
    "### Plots for Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t8Wsr6wG0T4h"
   },
   "source": [
    "We plot the progress of loss as training proceeds over number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsmF_2n307SP"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_metrics(train_metric, val_metric, metric_name, title, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    plt.plot(train_metric,color='blue',label=metric_name)\n",
    "    plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
    "\n",
    "plot_metrics(epochs_train_losses, epochs_val_losses, \"Loss\", \"Loss\", ylim=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27fXX7Yqyu5S"
   },
   "source": [
    "We plot the confusion matrix to visualize the true values against the values predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9n2XJ9MwpDS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_outputs = model(norm_test_X.values)\n",
    "plot_confusion_matrix(test_Y.values, tf.round(test_outputs), title='Confusion Matrix for Untrained Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = tf.math.confusion_matrix(test_Y.values, tf.round(test_outputs), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 1.0\n",
      "recall = 0.9767441860465116\n"
     ]
    }
   ],
   "source": [
    "tn = conf_matrix[0][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "fn = conf_matrix[1][0]\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(fn+tp)\n",
    "print(f\"precision = {precision}\")\n",
    "print(f\"recall = {recall}\")"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "TF3C2W2-1",
    "TF3C2W2-2",
    "TF3C2W2-3"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
